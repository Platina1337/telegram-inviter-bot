# -*- coding: utf-8 -*-
"""
Parser worker for executing parse tasks.
"""
import logging
import asyncio
import httpx
from typing import Dict, List, Optional
from datetime import datetime

from parser.database import Database
from parser.session_manager import SessionManager
from shared.models import ParseTask
from shared.user_files_manager import UserFilesManager

logger = logging.getLogger(__name__)


class ParserWorker:
    """Worker for executing parse tasks."""
    
    def __init__(self, db: Database, session_manager: SessionManager):
        self.db = db
        self.session_manager = session_manager
        self.running_tasks: Dict[int, asyncio.Task] = {}
        self.user_files_manager = UserFilesManager()
        self.http_client = httpx.AsyncClient(timeout=10.0)
        # Store unsaved members for each task (for saving on stop)
        self.task_unsaved_members: Dict[int, List[Dict]] = {}
        self.task_metadata: Dict[int, Dict] = {}
        # Track last heartbeat update time to avoid too frequent DB writes
        self._last_heartbeat: Dict[int, float] = {}
    
    async def start_parse_task(self, task_id: int) -> Dict:
        """Start a parse task."""
        if task_id in self.running_tasks:
            return {"success": False, "error": "Task already running"}
        
        task = await self.db.get_parse_task(task_id)
        if not task:
            return {"success": False, "error": "Task not found"}
        
        # Update status
        await self.db.update_parse_task(task_id, status='running')
        
        # Initialize unsaved members storage
        self.task_unsaved_members[task_id] = []
        
        # Start task in background
        async_task = asyncio.create_task(self._run_parse_task(task))
        self.running_tasks[task_id] = async_task
        
        # Start heartbeat tracking (will be updated during task execution)
        self._last_heartbeat[task_id] = 0  # Force first heartbeat update
        
        logger.info(f"Started parse task {task_id}")
        return {"success": True}
    
    async def _update_heartbeat_if_needed(self, task_id: int):
        """Update heartbeat if 60+ seconds passed since last update. Returns True if updated."""
        import time
        now = time.time()
        last = self._last_heartbeat.get(task_id, 0)
        if now - last >= 60:  # Update every 60 seconds minimum
            await self.db.update_parse_task(task_id, last_heartbeat=datetime.now().isoformat())
            self._last_heartbeat[task_id] = now
            return True
        return False
    
    async def stop_parse_task(self, task_id: int) -> Dict:
        """Stop a parse task and save any unsaved data."""
        # Clean up heartbeat tracking
        if task_id in self._last_heartbeat:
            del self._last_heartbeat[task_id]
        
        task = await self.db.get_parse_task(task_id)
        
        # Save unsaved members before stopping
        if task_id in self.task_unsaved_members and self.task_unsaved_members[task_id]:
            unsaved = self.task_unsaved_members[task_id]
            if task and unsaved:
                metadata = self.task_metadata.get(task_id, {
                    'source_group_id': task.source_group_id,
                    'source_group_title': task.source_group_title,
                    'filter_admins': task.filter_admins,
                    'filter_inactive': task.filter_inactive,
                    'inactive_days': task.inactive_threshold_days,
                    'parsed_at': datetime.now().isoformat()
                })
                
                logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(unsaved)} –Ω–µ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–µ—Ä–µ–¥ –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π –∑–∞–¥–∞—á–∏ {task_id}")
                filepath, total = self.user_files_manager.append_users_to_file(
                    task.file_name,
                    unsaved,
                    metadata
                )
                
                # Update saved count
                await self.db.update_parse_task(task_id, saved_count=total)
                
                # Clear unsaved
                self.task_unsaved_members[task_id] = []
                
                # Notify user
                await self._notify_user(
                    task.user_id,
                    f"‚è∏Ô∏è **–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω**\n\n"
                    f"üìù –§–∞–π–ª: `{task.file_name}`\n"
                    f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Ñ–∞–π–ª: `{total}` –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n"
                    f"üë• –í—Å–µ–≥–æ —Å–ø–∞—Ä—à–µ–Ω–æ: `{task.parsed_count}` –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
                )
        
        if task_id not in self.running_tasks:
            await self.db.update_parse_task(task_id, status='paused')
            return {"success": True, "message": "Task was not running, data saved"}
        
        # Cancel the task
        self.running_tasks[task_id].cancel()
        del self.running_tasks[task_id]
        
        await self.db.update_parse_task(task_id, status='paused')
        logger.info(f"Stopped parse task {task_id}")
        return {"success": True}
    
    async def _save_users_incremental(self, task: ParseTask, users: List[Dict]) -> int:
        """Save users to file incrementally. Returns total count in file."""
        if not users:
            return task.saved_count
        
        metadata = {
            'source_group_id': task.source_group_id,
            'source_group_title': task.source_group_title,
            'filter_admins': task.filter_admins,
            'filter_inactive': task.filter_inactive,
            'inactive_days': task.inactive_threshold_days,
            'parsed_at': datetime.now().isoformat()
        }
        
        self.task_metadata[task.id] = metadata
        
        filepath, total = self.user_files_manager.append_users_to_file(
            task.file_name,
            users,
            metadata
        )
        
        logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task.id} - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(users)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ —Ñ–∞–π–ª (–≤—Å–µ–≥–æ –≤ —Ñ–∞–π–ª–µ: {total})")
        
        return total
    
    async def _run_parse_task(self, task: ParseTask):
        """Execute the parse task."""
        task_id = task.id
        
        # Check source type - if channel, use channel comments parsing
        if task.source_type == 'channel':
            await self._run_channel_comments_parse_task(task)
            return
        
        # Check parse mode and delegate to appropriate method
        if task.parse_mode == 'message_based':
            await self._run_message_based_parse_task(task)
            return
        
        # Default: member_list mode
        await self._run_member_list_parse_task(task)

    async def _run_member_list_parse_task(self, task: ParseTask):
        """Execute member list based parse task."""
        task_id = task.id
        user_id = task.user_id
        session_consecutive_parsed = 0  # Track parsed users for session rotation
        unsaved_members: List[Dict] = []  # Track unsaved members for incremental saving
        
        try:
            logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –∑–∞–¥–∞—á–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ {task_id}: {task.file_name}")
            
            # Get available sessions
            available_sessions = task.available_sessions.copy() if task.available_sessions else []
            logger.info(f"üìã –ó–∞–¥–∞—á–∞ {task_id} - –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫: {available_sessions}")
            
            # If no sessions in task settings, use sessions assigned to "parsing" task
            if not available_sessions:
                logger.info(f"‚ö†Ô∏è –ó–∞–¥–∞—á–∞ {task_id} - —Å–µ—Å—Å–∏–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ—Å—Å–∏–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–µ –Ω–∞ –∑–∞–¥–∞—á—É 'parsing'")
                parsing_sessions = await self.db.get_sessions_for_task("parsing")
                available_sessions = [s.alias for s in parsing_sessions if s.alias]
                
                if not available_sessions:
                    logger.warning(f"‚ö†Ô∏è –ó–∞–¥–∞—á–∞ {task_id} - –Ω–µ—Ç —Å–µ—Å—Å–∏–π –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã—Ö –Ω–∞ 'parsing', –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ")
                    all_sessions = await self.session_manager.list_sessions()
                    available_sessions = [s['alias'] for s in all_sessions if s.get('alias')]
                
                if not available_sessions:
                    raise Exception("No sessions available for parsing")
                
                # Update task with available sessions
                await self.db.update_parse_task(task_id, available_sessions=available_sessions)
                logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —Å–µ—Å—Å–∏–∏: {available_sessions}")
            
            # Remove failed sessions
            available_sessions = [s for s in available_sessions if s and s not in task.failed_sessions]
            if not available_sessions:
                raise Exception("All sessions have failed")
            
            logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–µ—Å—Å–∏–∏ (–ø–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö): {available_sessions}")
            
            # Use current session or first available
            current_session = task.session_alias if task.session_alias in available_sessions else available_sessions[0]
            logger.info(f"üîê –ó–∞–¥–∞—á–∞ {task_id} - —Ç–µ–∫—É—â–∞—è —Å–µ—Å—Å–∏—è: {current_session}")
            
            # Get proxy info for logging
            proxy_info = await self.session_manager.get_proxy_info(current_session, task.use_proxy)
            proxy_str = f" —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ {proxy_info}" if proxy_info else " –±–µ–∑ –ø—Ä–æ–∫—Å–∏"
            logger.info(f"üåê –ó–∞–¥–∞—á–∞ {task_id} - –ø—Ä–æ–∫—Å–∏: {proxy_str}")
            
            # Get client
            client = await self.session_manager.get_client(current_session, use_proxy=task.use_proxy)
            if not client:
                raise Exception(f"Session {current_session} not available")
            
            logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –∫–ª–∏–µ–Ω—Ç –ø–æ–ª—É—á–µ–Ω –¥–ª—è —Å–µ—Å—Å–∏–∏ {current_session}{proxy_str}")
            
            # Get group members
            offset = task.current_offset
            limit_per_request = 200
            total_parsed = task.parsed_count
            saved_count = task.saved_count
            
            from datetime import datetime, timedelta, timezone
            
            save_every = task.save_every if task.save_every > 0 else 0
            
            # Load already saved user IDs to skip them when resuming
            already_saved_ids = self.user_files_manager.get_saved_user_ids(task.file_name)
            if already_saved_ids:
                logger.info(f"üìÇ –ó–∞–¥–∞—á–∞ {task_id} - –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(already_saved_ids)} —É–∂–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö ID –∏–∑ —Ñ–∞–π–ª–∞ (–ø—Ä–æ–ø—É—Å—Ç–∏–º –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ)")
            
            logger.info(f"üìä –ó–∞–¥–∞—á–∞ {task_id} - –Ω–∞—á–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: offset={offset}, —É–∂–µ —Å–ø–∞—Ä—à–µ–Ω–æ={total_parsed}, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ={saved_count}, –ª–∏–º–∏—Ç={task.limit or '–±–µ–∑ –ª–∏–º–∏—Ç–∞'}")
            logger.info(f"‚öôÔ∏è –ó–∞–¥–∞—á–∞ {task_id} - –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–æ—Ç–∞—Ü–∏–∏: –≤–∫–ª—é—á–µ–Ω–∞={task.rotate_sessions}, –∫–∞–∂–¥—ã–µ {task.rotate_every} –ø–æ–ª—å–∑.")
            logger.info(f"‚è±Ô∏è –ó–∞–¥–∞—á–∞ {task_id} - –∑–∞–¥–µ—Ä–∂–∫–∞: {task.delay_seconds} —Å–µ–∫ –∫–∞–∂–¥—ã–µ {task.delay_every} –ø–æ–ª—å–∑.")
            logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª –∫–∞–∂–¥—ã–µ: {save_every or '–≤ –∫–æ–Ω—Ü–µ'} –ø–æ–ª—å–∑.")
            logger.info(f"üö´ –ó–∞–¥–∞—á–∞ {task_id} - —Ñ–∏–ª—å—Ç—Ä—ã: –∏—Å–∫–ª—é—á–∞—Ç—å –∞–¥–º–∏–Ω–æ–≤={'–î–∞' if task.filter_admins else '–ù–µ—Ç'}, –∏—Å–∫–ª—é—á–∞—Ç—å –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö={'–î–∞' if task.filter_inactive else '–ù–µ—Ç'} (> {task.inactive_threshold_days} –¥–Ω.)")
            
            while True:
                # Check if task was cancelled
                if task_id not in self.running_tasks:
                    logger.info(f"‚èπÔ∏è –ó–∞–¥–∞—á–∞ {task_id} –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
                    break
                
                # Check limit
                if task.limit and total_parsed >= task.limit:
                    logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –¥–æ—Å—Ç–∏–≥–ª–∞ –ª–∏–º–∏—Ç–∞: {task.limit}")
                    await self.db.update_parse_task(task_id, status='completed')
                    break
                
                try:
                    # Get members batch
                    batch_limit = limit_per_request
                    
                    if task.limit:
                        remaining = task.limit - total_parsed
                        # We might need to fetch more because of filtering, but let's stick to simple logic
                        batch_limit = min(batch_limit, remaining + 50) # fetch a bit more than needed to account for filters
                    
                    logger.info(f"üì• –ó–∞–¥–∞—á–∞ {task_id} - –∑–∞–ø—Ä–æ—Å —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏–∑ '{task.source_group_title}': offset={offset}, limit={batch_limit} (—Å–µ—Å—Å–∏—è: {current_session}{proxy_str})")
                    
                    batch = await self.session_manager.get_group_members(
                        current_session,
                        task.source_group_id,
                        limit=batch_limit,
                        offset=offset,
                        username=task.source_username
                    )
                    
                    if not batch:
                        logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –±–æ–ª—å—à–µ –Ω–µ—Ç —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
                        await self.db.update_parse_task(task_id, status='completed')
                        break
                    
                    logger.info(f"üì¶ –ó–∞–¥–∞—á–∞ {task_id} - –ø–æ–ª—É—á–µ–Ω–æ {len(batch)} —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏–∑ API")
                    
                    # Process members one by one (like inviter does)
                    for member in batch:
                        # Check if task was cancelled
                        if task_id not in self.running_tasks:
                            logger.info(f"‚èπÔ∏è –ó–∞–¥–∞—á–∞ {task_id} –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                            break
                        
                        # Check limit
                        if task.limit and total_parsed >= task.limit:
                            logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –¥–æ—Å—Ç–∏–≥–ª–∞ –ª–∏–º–∏—Ç–∞: {task.limit}")
                            break
                        
                        member_id = member.get('id')
                        user_info = f"{member.get('username') or member.get('id')}"
                        
                        # 1. Filter admins - –¥–µ–ª–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫–∞–∫ –≤ –∏–Ω–≤–∞–π—Ç–∏–Ω–≥–µ
                        if task.filter_admins:
                            logger.debug(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞–¥–º–∏–Ω–∞ –¥–ª—è {user_info}")
                            try:
                                source_member = await client.get_chat_member(task.source_group_id, member_id)
                                raw_status = source_member.status
                                status_str = getattr(raw_status, "name", str(raw_status)).upper()
                                
                                if status_str in ['ADMINISTRATOR', 'CREATOR', 'OWNER']:
                                    logger.info(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø—Ä–æ–ø—É—Å–∫ –∞–¥–º–∏–Ω–∞: {user_info} (—Å—Ç–∞—Ç—É—Å –≤ –≥—Ä—É–ø–ø–µ: {status_str})")
                                    continue
                                else:
                                    logger.debug(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_info} –Ω–µ –∞–¥–º–∏–Ω (—Å—Ç–∞—Ç—É—Å: {status_str})")
                            except Exception as e:
                                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –Ω–µ –∞–¥–º–∏–Ω (–∫–∞–∫ –≤ –∏–Ω–≤–∞–π—Ç–∏–Ω–≥–µ)
                                logger.warning(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∞–¥–º–∏–Ω–∞ –¥–ª—è {user_info}: {e}. –°—á–∏—Ç–∞–µ–º –Ω–µ –∞–¥–º–∏–Ω–æ–º.")
                        
                        # 2. Filter inactive - –¥–µ–ª–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è last_online_date –∫–∞–∫ –≤ –∏–Ω–≤–∞–π—Ç–∏–Ω–≥–µ
                        if task.filter_inactive and task.inactive_threshold_days is not None:
                            logger.debug(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–ª—è {user_info} (–ø–æ—Ä–æ–≥: {task.inactive_threshold_days} –¥–Ω.)")
                            user_last_online = None
                            try:
                                # –ü–æ–ª—É—á–∞–µ–º last_online_date —á–µ—Ä–µ–∑ get_users (–∫–∞–∫ –≤ –∏–Ω–≤–∞–π—Ç–∏–Ω–≥–µ)
                                users = await client.get_users([member_id])
                                if users:
                                    user_obj = users[0]
                                    user_last_online = getattr(user_obj, 'last_online_date', None)
                            except Exception as e:
                                logger.warning(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å last_online_date –¥–ª—è {user_info}: {e}. –°—á–∏—Ç–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–º (–∫–∞–∫ –≤ –∏–Ω–≤–∞–π—Ç–∏–Ω–≥–µ).")
                            
                            # –ï—Å–ª–∏ last_online_date –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, —Å—á–∏—Ç–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∞–∫—Ç–∏–≤–Ω—ã–º (–∫–∞–∫ –≤ –∏–Ω–≤–∞–π—Ç–∏–Ω–≥–µ)
                            if user_last_online is None:
                                logger.debug(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_info}: last_online_date –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –°—á–∏—Ç–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–º (–Ω–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º).")
                            else:
                                # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ last_online_date, –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –¥–∞—Ç–µ (–∫–∞–∫ –≤ –∏–Ω–≤–∞–π—Ç–∏–Ω–≥–µ)
                                from datetime import datetime, timedelta
                                threshold_date = datetime.now() - timedelta(days=task.inactive_threshold_days)
                                days_since_online = (datetime.now() - user_last_online).days
                                
                                logger.debug(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_info}: –±—ã–ª –æ–Ω–ª–∞–π–Ω {days_since_online} –¥–Ω. –Ω–∞–∑–∞–¥ (–ø–æ—Ä–æ–≥: {task.inactive_threshold_days} –¥–Ω.)")
                                
                                if user_last_online < threshold_date:
                                    logger.info(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø—Ä–æ–ø—É—Å–∫ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ–≥–æ: {user_info} (–±—ã–ª –æ–Ω–ª–∞–π–Ω {days_since_online} –¥–Ω. –Ω–∞–∑–∞–¥, –ø–æ—Ä–æ–≥: {task.inactive_threshold_days} –¥–Ω.)")
                                    continue
                                else:
                                    logger.debug(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_info} –∞–∫—Ç–∏–≤–µ–Ω ({days_since_online} –¥–Ω. <= {task.inactive_threshold_days} –¥–Ω.)")
                        
                        # 3. Skip already saved users (for resume support)
                        if member_id in already_saved_ids:
                            logger.debug(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø—Ä–æ–ø—É—Å–∫ —É–∂–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ: {member.get('username') or member_id}")
                            continue
                        
                        # Add user to list
                        user_data = {
                            'id': member_id,
                            'username': member['username'],
                            'first_name': member['first_name'],
                            'last_name': member['last_name']
                        }
                        unsaved_members.append(user_data)
                        self.task_unsaved_members[task_id] = unsaved_members
                        already_saved_ids.add(member_id)  # Mark as processed to avoid duplicates in same run
                        total_parsed += 1
                        session_consecutive_parsed += 1
                        
                        logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –¥–æ–±–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å #{total_parsed}: {user_data.get('username') or user_data.get('id')} (—Å–µ—Å—Å–∏—è: {current_session})")
                        
                        # Update progress in DB
                        await self.db.update_parse_task(
                            task_id,
                            parsed_count=total_parsed
                        )
                        
                        # Check for incremental save
                        if save_every > 0 and len(unsaved_members) >= save_every:
                            saved_count = await self._save_users_incremental(task, unsaved_members)
                            await self.db.update_parse_task(task_id, saved_count=saved_count)
                            unsaved_members = []  # Clear after save
                            self.task_unsaved_members[task_id] = unsaved_members
                            logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: {saved_count} –ø–æ–ª—å–∑. –≤ —Ñ–∞–π–ª–µ")
                        
                        # Check for session rotation based on parsed count
                        if task.rotate_sessions and task.rotate_every > 0 and session_consecutive_parsed >= task.rotate_every:
                            if available_sessions and len(available_sessions) > 1:
                                logger.info(f"üîÑ –ó–∞–¥–∞—á–∞ {task_id} - —Å–µ—Å—Å–∏—è {current_session} –æ–±—Ä–∞–±–æ—Ç–∞–ª–∞ {session_consecutive_parsed} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π. –†–æ—Ç–∞—Ü–∏—è...")
                                
                                try:
                                    current_index = available_sessions.index(current_session)
                                except ValueError:
                                    current_index = -1
                                    
                                next_index = (current_index + 1) % len(available_sessions)
                                next_session = available_sessions[next_index]
                                
                                if next_session != current_session:
                                    # Get proxy info for new session
                                    new_proxy_info = await self.session_manager.get_proxy_info(next_session, task.use_proxy)
                                    new_proxy_str = f" —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ {new_proxy_info}" if new_proxy_info else " –±–µ–∑ –ø—Ä–æ–∫—Å–∏"
                                    
                                    logger.info(f"üîÑ –ó–∞–¥–∞—á–∞ {task_id} - —Ä–æ—Ç–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏: {current_session}{proxy_str} -> {next_session}{new_proxy_str}")
                                    current_session = next_session
                                    proxy_str = new_proxy_str
                                    session_consecutive_parsed = 0  # Reset counter
                                    
                                    await self.db.update_parse_task(task_id, session_alias=current_session)
                                    
                                    # Update client for next iteration
                                    client = await self.session_manager.get_client(current_session, use_proxy=task.use_proxy)
                                    if not client:
                                        logger.error(f"‚ùå –ó–∞–¥–∞—á–∞ {task_id} - –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Å–µ—Å—Å–∏–∏ {current_session}")
                                        raise Exception(f"Failed to get client for session {current_session}")
                                    
                                    logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –∫–ª–∏–µ–Ω—Ç –æ–±–Ω–æ–≤–ª–µ–Ω –¥–ª—è —Å–µ—Å—Å–∏–∏ {current_session}{proxy_str}")
                            else:
                                logger.warning(f"‚ö†Ô∏è –ó–∞–¥–∞—á–∞ {task_id} - —Ä–æ—Ç–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞, –Ω–æ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∞ —Å–µ—Å—Å–∏—è")
                        
                        # Apply delay after every N parsed users
                        if task.delay_seconds > 0 and task.delay_every > 0:
                            if total_parsed % task.delay_every == 0:
                                logger.info(f"‚è±Ô∏è –ó–∞–¥–∞—á–∞ {task_id} - –∑–∞–¥–µ—Ä–∂–∫–∞ {task.delay_seconds} —Å–µ–∫ –ø–æ—Å–ª–µ {total_parsed} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
                                await asyncio.sleep(task.delay_seconds)
                    
                    # Update offset for next batch
                    offset += len(batch)
                    await self.db.update_parse_task(task_id, current_offset=offset)
                    
                    # If batch was smaller than limit, we've reached the end
                    if len(batch) < batch_limit:
                        logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü —Å–ø–∏—Å–∫–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ (–ø–æ–ª—É—á–µ–Ω–æ {len(batch)} < {batch_limit})")
                        await self.db.update_parse_task(task_id, status='completed')
                        break
                    
                    # Also stop if we reached the limit
                    if task.limit and total_parsed >= task.limit:
                        logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞: {total_parsed}/{task.limit}")
                        await self.db.update_parse_task(task_id, status='completed')
                        break
                
                except Exception as e:
                    logger.error(f"‚ùå –ó–∞–¥–∞—á–∞ {task_id} - –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {e}", exc_info=True)
                    
                    # Try rotating session on error
                    if task.rotate_sessions and len(available_sessions) > 1:
                        logger.info(f"üîÑ –ó–∞–¥–∞—á–∞ {task_id} - –ø–æ–ø—ã—Ç–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏ —Å–µ—Å—Å–∏–∏ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏...")
                        
                        try:
                            current_index = available_sessions.index(current_session)
                        except ValueError:
                            current_index = -1
                            
                        next_index = (current_index + 1) % len(available_sessions)
                        next_session = available_sessions[next_index]
                        
                        # Get proxy info for new session
                        new_proxy_info = await self.session_manager.get_proxy_info(next_session, task.use_proxy)
                        new_proxy_str = f" —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ {new_proxy_info}" if new_proxy_info else " –±–µ–∑ –ø—Ä–æ–∫—Å–∏"
                        
                        logger.info(f"üîÑ –ó–∞–¥–∞—á–∞ {task_id} - —Ä–æ—Ç–∞—Ü–∏—è –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {current_session}{proxy_str} -> {next_session}{new_proxy_str}")
                        current_session = next_session
                        proxy_str = new_proxy_str
                        session_consecutive_parsed = 0  # Reset counter
                        
                        client = await self.session_manager.get_client(current_session, use_proxy=task.use_proxy)
                        if not client:
                            logger.error(f"‚ùå –ó–∞–¥–∞—á–∞ {task_id} - –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–æ—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —Å–µ—Å—Å–∏—é {current_session}")
                            raise Exception(f"Failed to rotate to session {current_session}")
                        
                        await self.db.update_parse_task(task_id, session_alias=current_session)
                        logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - —É—Å–ø–µ—à–Ω–∞—è —Ä–æ—Ç–∞—Ü–∏—è –Ω–∞ —Å–µ—Å—Å–∏—é {current_session}{proxy_str}, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
                        continue
                    else:
                        logger.error(f"‚ùå –ó–∞–¥–∞—á–∞ {task_id} - —Ä–æ—Ç–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏")
                        raise
            
            # Save remaining users to file at the end
            if unsaved_members:
                saved_count = await self._save_users_incremental(task, unsaved_members)
                await self.db.update_parse_task(task_id, saved_count=saved_count)
                unsaved_members = []
                self.task_unsaved_members[task_id] = unsaved_members
                logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: {saved_count} –ø–æ–ª—å–∑. –≤ —Ñ–∞–π–ª–µ")
            
            if saved_count > 0:
                logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
                
                # Notify user
                await self._notify_user(
                    user_id, 
                    f"‚úÖ **–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!**\n\n"
                    f"üìù –§–∞–π–ª: `{task.file_name}`\n"
                    f"üë• –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: `{saved_count}` –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.\n"
                    f"üìÇ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ `user_files/`"
                )
            else:
                logger.warning(f"‚ö†Ô∏è –ó–∞–¥–∞—á–∞ {task_id} - –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
                await self._notify_user(
                    user_id, 
                    f"‚ö†Ô∏è **–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω, –Ω–æ —É—á–∞—Å—Ç–Ω–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.**\n\n"
                    f"–í–æ–∑–º–æ–∂–Ω–æ, —Å–ø–∏—Å–æ–∫ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Å–∫—Ä—ã—Ç –∏–ª–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã —Å–ª–∏—à–∫–æ–º —Å—Ç—Ä–æ–≥–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã."
                )
            
            # Mark as completed
            await self.db.update_parse_task(task_id, status='completed')
            logger.info(f"üéâ –ó–∞–¥–∞—á–∞ {task_id} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
        except asyncio.CancelledError:
            logger.info(f"‚èπÔ∏è –ó–∞–¥–∞—á–∞ {task_id} –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            # Save any unsaved data on cancel
            if unsaved_members:
                saved_count = await self._save_users_incremental(task, unsaved_members)
                await self.db.update_parse_task(task_id, saved_count=saved_count)
                logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(unsaved_members)} –ø–æ–ª—å–∑. –ø—Ä–∏ –æ—Ç–º–µ–Ω–µ (–≤—Å–µ–≥–æ: {saved_count})")
            await self.db.update_parse_task(task_id, status='paused')
        except Exception as e:
            logger.error(f"üí• –ó–∞–¥–∞—á–∞ {task_id} –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π: {e}", exc_info=True)
            # Save any unsaved data on error
            if unsaved_members:
                try:
                    saved_count = await self._save_users_incremental(task, unsaved_members)
                    await self.db.update_parse_task(task_id, saved_count=saved_count)
                    logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(unsaved_members)} –ø–æ–ª—å–∑. –ø—Ä–∏ –æ—à–∏–±–∫–µ (–≤—Å–µ–≥–æ: {saved_count})")
                except Exception as save_error:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ: {save_error}")
            await self.db.update_parse_task(
                task_id,
                status='failed',
                error_message=str(e)
            )
            await self._notify_user(user_id, f"‚ùå **–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞!**\n\n–ó–∞–¥–∞—á–∞: `{task.file_name}`\n–û—à–∏–±–∫–∞: `{str(e)}`")
        finally:
            # Remove from running tasks
            if task_id in self.running_tasks:
                del self.running_tasks[task_id]
                logger.info(f"üßπ –ó–∞–¥–∞—á–∞ {task_id} —É–¥–∞–ª–µ–Ω–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á")
            # Clean up heartbeat tracking
            if task_id in self._last_heartbeat:
                del self._last_heartbeat[task_id]
            # Clean up unsaved members storage
            if task_id in self.task_unsaved_members:
                del self.task_unsaved_members[task_id]
            if task_id in self.task_metadata:
                del self.task_metadata[task_id]


    async def _notify_user(self, user_id: int, text: str):
        """Send a notification to user via bot (using HTTP API)."""
        from parser.config import config
        
        if not config.BOT_TOKEN:
            return
            
        try:
            url = f"https://api.telegram.org/bot{config.BOT_TOKEN}/sendMessage"
            payload = {
                "chat_id": user_id,
                "text": text,
                "parse_mode": "Markdown"
            }
            
            response = await self.http_client.post(url, json=payload)
            if response.status_code != 200:
                logger.error(f"Failed to send notification: {response.text}")
        except Exception as e:
            logger.error(f"Failed to send notification to user {user_id}: {e}")

    async def _run_message_based_parse_task(self, task: ParseTask):
        """Execute message-based parse task - parses users from chat history based on their messages.
        
        This method works differently from member_list mode:
        1. Iterates through chat message history (not member list)
        2. For each message, checks if author matches keyword/exclude filters
        3. Saves matching users incrementally to file (not in memory)
        4. All settings (delay, rotation, save_every) apply to API requests/found users on stage 1
        """
        task_id = task.id
        user_id = task.user_id
        unsaved_members: List[Dict] = []
        
        try:
            logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –∑–∞–¥–∞—á–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º {task_id}: {task.file_name}")
            logger.info(f"üìã –†–µ–∂–∏–º: –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º")
            logger.info(f"üîë –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {task.keyword_filter if task.keyword_filter else '–Ω–µ—Ç'}")
            logger.info(f"üö´ –°–ª–æ–≤–∞ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è: {task.exclude_keywords if task.exclude_keywords else '–Ω–µ—Ç'}")
            logger.info(f"üìä –õ–∏–º–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–π: {task.messages_limit if task.messages_limit else '–±–µ–∑ –ª–∏–º–∏—Ç–∞'}")
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–∞–∂–¥—ã–µ: {task.save_every_users} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π" if task.save_every_users > 0 else "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: –≤ –∫–æ–Ω—Ü–µ")
            logger.info(f"‚è±Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞: {task.delay_seconds} —Å–µ–∫ –∫–∞–∂–¥—ã–µ {task.delay_every_requests} –∑–∞–ø—Ä–æ—Å–æ–≤")
            logger.info(f"üîÑ –†–æ—Ç–∞—Ü–∏—è: –∫–∞–∂–¥—ã–µ {task.rotate_every_requests} –∑–∞–ø—Ä–æ—Å–æ–≤" if task.rotate_every_requests > 0 else "üîÑ –†–æ—Ç–∞—Ü–∏—è: —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö")
            
            # Get available sessions
            available_sessions = task.available_sessions.copy() if task.available_sessions else []
            
            if not available_sessions:
                parsing_sessions = await self.db.get_sessions_for_task("parsing")
                available_sessions = [s.alias for s in parsing_sessions if s.alias]
                
                if not available_sessions:
                    all_sessions = await self.session_manager.list_sessions()
                    available_sessions = [s['alias'] for s in all_sessions if s.get('alias')]
                
                if not available_sessions:
                    raise Exception("No sessions available for parsing")
                
                await self.db.update_parse_task(task_id, available_sessions=available_sessions)
            
            # Remove failed sessions
            available_sessions = [s for s in available_sessions if s and s not in task.failed_sessions]
            if not available_sessions:
                raise Exception("All sessions have failed")
            
            # Use current session or first available
            current_session = task.session_alias if task.session_alias in available_sessions else available_sessions[0]
            
            # Get proxy info
            proxy_info = await self.session_manager.get_proxy_info(current_session, task.use_proxy)
            proxy_str = f" —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ {proxy_info}" if proxy_info else " –±–µ–∑ –ø—Ä–æ–∫—Å–∏"
            
            # Get client
            client = await self.session_manager.get_client(current_session, use_proxy=task.use_proxy)
            if not client:
                raise Exception(f"Session {current_session} not available")
            
            logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –∫–ª–∏–µ–Ω—Ç –ø–æ–ª—É—á–µ–Ω –¥–ª—è —Å–µ—Å—Å–∏–∏ {current_session}{proxy_str}")
            
            # Initialize counters
            total_unique_users = 0  # Total unique users found (matching keywords/exclude criteria)
            saved_count = task.saved_count
            processed_messages = task.messages_offset  # Resume from where we left off
            api_requests_count = 0  # Count API requests for delay/rotation
            
            # Load already saved user IDs to skip duplicates
            already_saved_ids = self.user_files_manager.get_saved_user_ids(task.file_name)
            if already_saved_ids:
                logger.info(f"üìÇ –ó–∞–¥–∞—á–∞ {task_id} - –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(already_saved_ids)} —É–∂–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö ID –∏–∑ —Ñ–∞–π–ª–∞ (–ø—Ä–æ–ø—É—Å—Ç–∏–º)")
            
            # Track seen users in this run to avoid duplicates within same run
            seen_user_ids = set()
            
            logger.info(f"üìä –ó–∞–¥–∞—á–∞ {task_id} - –Ω–∞—á–∞–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞ {task.source_group_title}")
            if processed_messages > 0:
                logger.info(f"üîÑ –ó–∞–¥–∞—á–∞ {task_id} - –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å —Å–æ–æ–±—â–µ–Ω–∏—è #{processed_messages}")
            
            # Join source group if needed
            await self.session_manager.join_chat_if_needed(
                client, 
                task.source_group_id, 
                task.source_username
            )
            
            # Iterate through chat history
            async for message in client.get_chat_history(task.source_group_id, offset=task.messages_offset):
                # Check if task was cancelled
                if task_id not in self.running_tasks:
                    logger.info(f"‚èπÔ∏è –ó–∞–¥–∞—á–∞ {task_id} –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
                    break
                
                processed_messages += 1
                
                # Log progress every 100 messages
                if processed_messages % 100 == 0:
                    logger.info(
                        f"üì® –ó–∞–¥–∞—á–∞ {task_id} - –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_messages} —Å–æ–æ–±—â–µ–Ω–∏–π, "
                        f"–Ω–∞–π–¥–µ–Ω–æ {total_unique_users} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, "
                        f"—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Ñ–∞–π–ª: {saved_count}"
                    )
                
                # Check messages limit
                if task.messages_limit and processed_messages >= task.messages_limit:
                    logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º: {task.messages_limit}")
                    break
                
                # Count API requests (approximately every 100 messages = 1 request)
                if processed_messages % 100 == 0:
                    api_requests_count += 1
                    
                    # Check for delay after N requests
                    if task.delay_every_requests > 0 and api_requests_count % task.delay_every_requests == 0:
                        logger.info(f"‚è±Ô∏è –ó–∞–¥–∞—á–∞ {task_id} - –∑–∞–¥–µ—Ä–∂–∫–∞ {task.delay_seconds} —Å–µ–∫ –ø–æ—Å–ª–µ {api_requests_count} –∑–∞–ø—Ä–æ—Å–æ–≤")
                        await asyncio.sleep(task.delay_seconds)
                    
                    # Check for session rotation after N requests
                    if task.rotate_sessions and task.rotate_every_requests > 0 and api_requests_count % task.rotate_every_requests == 0:
                        if len(available_sessions) > 1:
                            logger.info(f"üîÑ –ó–∞–¥–∞—á–∞ {task_id} - —Ä–æ—Ç–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏ –ø–æ—Å–ª–µ {api_requests_count} –∑–∞–ø—Ä–æ—Å–æ–≤...")
                            
                            try:
                                current_index = available_sessions.index(current_session)
                            except ValueError:
                                current_index = -1
                            
                            next_index = (current_index + 1) % len(available_sessions)
                            next_session = available_sessions[next_index]
                            
                            if next_session != current_session:
                                new_proxy_info = await self.session_manager.get_proxy_info(next_session, task.use_proxy)
                                new_proxy_str = f" —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ {new_proxy_info}" if new_proxy_info else " –±–µ–∑ –ø—Ä–æ–∫—Å–∏"
                                
                                logger.info(f"üîÑ –ó–∞–¥–∞—á–∞ {task_id} - —Ä–æ—Ç–∞—Ü–∏—è: {current_session}{proxy_str} -> {next_session}{new_proxy_str}")
                                current_session = next_session
                                proxy_str = new_proxy_str
                                
                                await self.db.update_parse_task(task_id, session_alias=current_session)
                                
                                client = await self.session_manager.get_client(current_session, use_proxy=task.use_proxy)
                                if not client:
                                    raise Exception(f"Failed to get client for session {current_session}")
                
                # Get message author
                user = message.from_user
                if not user or user.is_bot:
                    continue
                
                msg_user_id = user.id
                
                # Skip if already saved or seen in this run
                if msg_user_id in already_saved_ids or msg_user_id in seen_user_ids:
                    continue
                
                # Get message text
                msg_text = message.text or message.caption or ""
                msg_text_lower = msg_text.lower()
                
                # Check for keywords
                has_keyword = False
                if task.keyword_filter:
                    for keyword in task.keyword_filter:
                        if keyword.lower() in msg_text_lower:
                            has_keyword = True
                            break
                else:
                    # No keyword filter = all match
                    has_keyword = True
                
                if not has_keyword:
                    continue
                
                # Check for exclude keywords
                has_exclude = False
                if task.exclude_keywords:
                    for exclude_word in task.exclude_keywords:
                        if exclude_word.lower() in msg_text_lower:
                            has_exclude = True
                            break
                
                if has_exclude:
                    continue
                
                # User matches keyword criteria - mark as seen and add to unique count
                seen_user_ids.add(msg_user_id)
                total_unique_users += 1
                
                user_data = {
                    'id': msg_user_id,
                    'username': user.username,
                    'first_name': user.first_name,
                    'last_name': user.last_name
                }
                user_info = f"{user_data.get('username') or user_data.get('id')}"
                
                # Apply admin filter if enabled
                if task.filter_admins:
                    try:
                        source_member = await client.get_chat_member(task.source_group_id, msg_user_id)
                        raw_status = source_member.status
                        status_str = getattr(raw_status, "name", str(raw_status)).upper()
                        
                        if status_str in ['ADMINISTRATOR', 'CREATOR', 'OWNER']:
                            logger.info(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø—Ä–æ–ø—É—Å–∫ –∞–¥–º–∏–Ω–∞: {user_info}")
                            continue
                    except Exception as e:
                        logger.warning(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∞–¥–º–∏–Ω–∞ –¥–ª—è {user_info}: {e}")
                
                # Apply inactive filter if enabled
                if task.filter_inactive and task.inactive_threshold_days is not None:
                    try:
                        users = await client.get_users([msg_user_id])
                        if users:
                            user_obj = users[0]
                            user_last_online = getattr(user_obj, 'last_online_date', None)
                            
                            if user_last_online is not None:
                                from datetime import datetime, timedelta
                                threshold_date = datetime.now() - timedelta(days=task.inactive_threshold_days)
                                
                                if user_last_online < threshold_date:
                                    days_since_online = (datetime.now() - user_last_online).days
                                    logger.info(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø—Ä–æ–ø—É—Å–∫ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ–≥–æ: {user_info} ({days_since_online} –¥–Ω.)")
                                    continue
                    except Exception as e:
                        logger.warning(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è {user_info}: {e}")
                
                # User passed all filters - add to unsaved list
                unsaved_members.append(user_data)
                self.task_unsaved_members[task_id] = unsaved_members
                already_saved_ids.add(msg_user_id)
                
                logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –Ω–∞–π–¥–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å #{total_unique_users}: {user_info}")
                
                # Update messages offset in DB for resume capability
                await self.db.update_parse_task(task_id, messages_offset=processed_messages, parsed_count=total_unique_users)
                
                # Check for incremental save by unique users found
                if task.save_every_users > 0 and len(unsaved_members) >= task.save_every_users:
                    saved_count = await self._save_users_incremental(task, unsaved_members)
                    await self.db.update_parse_task(task_id, saved_count=saved_count)
                    unsaved_members = []
                    self.task_unsaved_members[task_id] = unsaved_members
                    logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(unsaved_members)} –ø–æ–ª—å–∑., –≤—Å–µ–≥–æ –≤ —Ñ–∞–π–ª–µ: {saved_count}")
            
            # Save remaining users
            if unsaved_members:
                saved_count = await self._save_users_incremental(task, unsaved_members)
                await self.db.update_parse_task(task_id, saved_count=saved_count)
                logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: –≤—Å–µ–≥–æ –≤ —Ñ–∞–π–ª–µ {saved_count} –ø–æ–ª—å–∑.")
                unsaved_members = []
                self.task_unsaved_members[task_id] = unsaved_members
            
            # Mark as completed
            await self.db.update_parse_task(task_id, status='completed')
            logger.info(f"üéâ –ó–∞–¥–∞—á–∞ {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_messages} —Å–æ–æ–±—â–µ–Ω–∏–π, –Ω–∞–π–¥–µ–Ω–æ {total_unique_users} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.")
            
            # Notify user
            await self._notify_user(
                user_id,
                f"‚úÖ **–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!**\n\n"
                f"üìù –§–∞–π–ª: `{task.file_name}`\n"
                f"üì§ –ì—Ä—É–ø–ø–∞: {task.source_group_title}\n"
                f"üìã –†–µ–∂–∏–º: –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º\n"
                f"üì® –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {processed_messages}\n"
                f"üë• –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {total_unique_users}\n"
                f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Ñ–∞–π–ª: {saved_count}"
            )
            
        except asyncio.CancelledError:
            logger.info(f"‚èπÔ∏è –ó–∞–¥–∞—á–∞ {task_id} –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            # Save unsaved data
            if unsaved_members:
                saved_count = await self._save_users_incremental(task, unsaved_members)
                await self.db.update_parse_task(task_id, saved_count=saved_count)
                logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(unsaved_members)} –ø–æ–ª—å–∑. –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ, –≤—Å–µ–≥–æ: {saved_count}")
            await self.db.update_parse_task(task_id, status='paused')
            
            # Notify user
            await self._notify_user(
                user_id,
                f"‚è∏Ô∏è **–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω**\n\n"
                f"üìù –§–∞–π–ª: `{task.file_name}`\n"
                f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Ñ–∞–π–ª: `{saved_count}` –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
            )
        except Exception as e:
            error_str = str(e)
            logger.error(f"üí• –ó–∞–¥–∞—á–∞ {task_id} –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π: {error_str}", exc_info=True)
            
            # Check if it's a flood wait error and we can rotate
            is_flood_wait = 'FloodWait' in error_str or 'flood' in error_str.lower()
            
            if is_flood_wait and task.rotate_sessions and len(available_sessions) > 1:
                logger.warning(f"‚ö†Ô∏è –ó–∞–¥–∞—á–∞ {task_id} - –æ–±–Ω–∞—Ä—É–∂–µ–Ω FloodWait, –ø–æ–ø—ã—Ç–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏ —Å–µ—Å—Å–∏–∏...")
                
                # Save unsaved data first
                if unsaved_members:
                    try:
                        saved_count = await self._save_users_incremental(task, unsaved_members)
                        await self.db.update_parse_task(task_id, saved_count=saved_count)
                        logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(unsaved_members)} –ø–æ–ª—å–∑. –ø–µ—Ä–µ–¥ —Ä–æ—Ç–∞—Ü–∏–µ–π")
                    except Exception as save_error:
                        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ: {save_error}")
                
                # Try rotating to next session
                try:
                    current_index = available_sessions.index(current_session)
                except ValueError:
                    current_index = -1
                
                next_index = (current_index + 1) % len(available_sessions)
                next_session = available_sessions[next_index]
                
                if next_session != current_session:
                    logger.info(f"üîÑ –ó–∞–¥–∞—á–∞ {task_id} - —Ä–æ—Ç–∞—Ü–∏—è –∏–∑-–∑–∞ FloodWait: {current_session} -> {next_session}")
                    await self.db.update_parse_task(task_id, session_alias=next_session, status='paused')
                    await self._notify_user(
                        user_id,
                        f"‚ö†Ô∏è **FloodWait –Ω–∞ —Å–µ—Å—Å–∏–∏ {current_session}**\n\n"
                        f"–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –°–µ—Å—Å–∏—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∞ –Ω–∞ `{next_session}`.\n"
                        f"–ù–∞–∂–º–∏—Ç–µ '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å' —á—Ç–æ–±—ã –≤–æ–∑–æ–±–Ω–æ–≤–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥."
                    )
                    return
            
            # Save unsaved data on error
            if unsaved_members:
                try:
                    saved_count = await self._save_users_incremental(task, unsaved_members)
                    await self.db.update_parse_task(task_id, saved_count=saved_count)
                    logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(unsaved_members)} –ø–æ–ª—å–∑. –ø—Ä–∏ –æ—à–∏–±–∫–µ, –≤—Å–µ–≥–æ: {saved_count}")
                except Exception as save_error:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ: {save_error}")
            
            await self.db.update_parse_task(
                task_id,
                status='failed',
                error_message=error_str
            )
            await self._notify_user(
                user_id,
                f"‚ùå **–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞!**\n\n"
                f"–ó–∞–¥–∞—á–∞: `{task.file_name}`\n"
                f"–û—à–∏–±–∫–∞: `{error_str}`"
            )
        finally:
            if task_id in self.running_tasks:
                del self.running_tasks[task_id]
            if task_id in self.task_unsaved_members:
                del self.task_unsaved_members[task_id]
            if task_id in self.task_metadata:
                del self.task_metadata[task_id]

    async def _run_channel_comments_parse_task(self, task: ParseTask):
        """Execute channel comments parse task - parses users from comments under channel posts.
        
        This method works specifically for channels:
        1. Iterates through channel posts (message history)
        2. For each post, gets discussion/comments (replies)
        3. Extracts users who commented
        4. Applies keyword/exclude filters to comment text
        5. Saves matching users incrementally to file
        """
        # Force disable admin/inactive filters for channel comments as they are not relevant/needed
        task.filter_admins = False
        task.filter_inactive = False

        task_id = task.id
        user_id = task.user_id
        unsaved_members: List[Dict] = []
        
        try:
            logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –∑–∞–¥–∞—á–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫–∞–Ω–∞–ª–∞ {task_id}: {task.file_name}")
            logger.info(f"üì¢ –ö–∞–Ω–∞–ª: {task.source_group_title}")
            logger.info(f"üîë –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {task.keyword_filter if task.keyword_filter else '–Ω–µ—Ç'}")
            logger.info(f"üö´ –°–ª–æ–≤–∞ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è: {task.exclude_keywords if task.exclude_keywords else '–Ω–µ—Ç'}")
            logger.info(f"üìä –õ–∏–º–∏—Ç –ø–æ—Å—Ç–æ–≤: {task.messages_limit if task.messages_limit else '–±–µ–∑ –ª–∏–º–∏—Ç–∞'}")
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–∞–∂–¥—ã–µ: {task.save_every_users} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π" if task.save_every_users > 0 else "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: –≤ –∫–æ–Ω—Ü–µ")
            logger.info(f"‚è±Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞: {task.delay_seconds} —Å–µ–∫ –∫–∞–∂–¥—ã–µ {task.delay_every_requests} –∑–∞–ø—Ä–æ—Å–æ–≤")
            logger.info(f"üîÑ –†–æ—Ç–∞—Ü–∏—è: –∫–∞–∂–¥—ã–µ {task.rotate_every_requests} –∑–∞–ø—Ä–æ—Å–æ–≤" if task.rotate_every_requests > 0 else "üîÑ –†–æ—Ç–∞—Ü–∏—è: —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö")
            
            # Get available sessions
            available_sessions = task.available_sessions.copy() if task.available_sessions else []
            
            if not available_sessions:
                parsing_sessions = await self.db.get_sessions_for_task("parsing")
                available_sessions = [s.alias for s in parsing_sessions if s.alias]
                
                if not available_sessions:
                    all_sessions = await self.session_manager.list_sessions()
                    available_sessions = [s['alias'] for s in all_sessions if s.get('alias')]
                
                if not available_sessions:
                    raise Exception("No sessions available for parsing")
                
                await self.db.update_parse_task(task_id, available_sessions=available_sessions)
            
            # Remove failed sessions
            available_sessions = [s for s in available_sessions if s and s not in task.failed_sessions]
            if not available_sessions:
                raise Exception("All sessions have failed")
            
            # Use current session or first available
            current_session = task.session_alias if task.session_alias in available_sessions else available_sessions[0]
            
            # Get proxy info
            proxy_info = await self.session_manager.get_proxy_info(current_session, task.use_proxy)
            proxy_str = f" —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ {proxy_info}" if proxy_info else " –±–µ–∑ –ø—Ä–æ–∫—Å–∏"
            
            # Get client
            client = await self.session_manager.get_client(current_session, use_proxy=task.use_proxy)
            if not client:
                raise Exception(f"Session {current_session} not available")
            
            logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –∫–ª–∏–µ–Ω—Ç –ø–æ–ª—É—á–µ–Ω –¥–ª—è —Å–µ—Å—Å–∏–∏ {current_session}{proxy_str}")
            
            # Initialize counters
            total_unique_users = 0  # Total unique users found (matching keywords/exclude criteria)
            saved_count = task.saved_count
            processed_posts = task.messages_offset  # Resume from where we left off
            api_requests_count = 0  # Count API requests for delay/rotation
            
            # Load already saved user IDs to skip duplicates
            already_saved_ids = self.user_files_manager.get_saved_user_ids(task.file_name)
            if already_saved_ids:
                logger.info(f"üìÇ –ó–∞–¥–∞—á–∞ {task_id} - –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(already_saved_ids)} —É–∂–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö ID –∏–∑ —Ñ–∞–π–ª–∞ (–ø—Ä–æ–ø—É—Å—Ç–∏–º)")
            
            # Track seen users in this run to avoid duplicates within same run
            seen_user_ids = set()
            
            logger.info(f"üìä –ó–∞–¥–∞—á–∞ {task_id} - –Ω–∞—á–∞–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–æ –ø–æ—Å—Ç–∞–º –∫–∞–Ω–∞–ª–∞ {task.source_group_title}")
            if processed_posts > 0:
                logger.info(f"üîÑ –ó–∞–¥–∞—á–∞ {task_id} - –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å –ø–æ—Å—Ç–∞ #{processed_posts}")
            
            # Join channel if needed
            await self.session_manager.join_chat_if_needed(
                client, 
                task.source_group_id, 
                task.source_username
            )
            
            # Iterate through channel posts
            async for post in client.get_chat_history(task.source_group_id, offset=task.messages_offset):
                # Check if task was cancelled
                if task_id not in self.running_tasks:
                    logger.info(f"‚èπÔ∏è –ó–∞–¥–∞—á–∞ {task_id} –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
                    break
                
                processed_posts += 1
                
                # Log progress every 10 posts
                if processed_posts % 10 == 0:
                    logger.info(
                        f"üì® –ó–∞–¥–∞—á–∞ {task_id} - –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_posts} –ø–æ—Å—Ç–æ–≤, "
                        f"–Ω–∞–π–¥–µ–Ω–æ {total_unique_users} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, "
                        f"—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Ñ–∞–π–ª: {saved_count}"
                    )
                
                # Check posts limit
                if task.messages_limit and processed_posts >= task.messages_limit:
                    logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–æ –ø–æ—Å—Ç–∞–º: {task.messages_limit}")
                    break
                
                # Count API requests
                api_requests_count += 1
                
                # Check for delay after N requests
                if task.delay_every_requests > 0 and api_requests_count % task.delay_every_requests == 0:
                    logger.info(f"‚è±Ô∏è –ó–∞–¥–∞—á–∞ {task_id} - –∑–∞–¥–µ—Ä–∂–∫–∞ {task.delay_seconds} —Å–µ–∫ –ø–æ—Å–ª–µ {api_requests_count} –∑–∞–ø—Ä–æ—Å–æ–≤")
                    await asyncio.sleep(task.delay_seconds)
                
                # Check for session rotation after N requests
                if task.rotate_sessions and task.rotate_every_requests > 0 and api_requests_count % task.rotate_every_requests == 0:
                    if len(available_sessions) > 1:
                        logger.info(f"üîÑ –ó–∞–¥–∞—á–∞ {task_id} - —Ä–æ—Ç–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏ –ø–æ—Å–ª–µ {api_requests_count} –∑–∞–ø—Ä–æ—Å–æ–≤...")
                        
                        try:
                            current_index = available_sessions.index(current_session)
                        except ValueError:
                            current_index = -1
                        
                        next_index = (current_index + 1) % len(available_sessions)
                        next_session = available_sessions[next_index]
                        
                        if next_session != current_session:
                            new_proxy_info = await self.session_manager.get_proxy_info(next_session, task.use_proxy)
                            new_proxy_str = f" —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ {new_proxy_info}" if new_proxy_info else " –±–µ–∑ –ø—Ä–æ–∫—Å–∏"
                            
                            logger.info(f"üîÑ –ó–∞–¥–∞—á–∞ {task_id} - —Ä–æ—Ç–∞—Ü–∏—è: {current_session}{proxy_str} -> {next_session}{new_proxy_str}")
                            current_session = next_session
                            proxy_str = new_proxy_str
                            
                            await self.db.update_parse_task(task_id, session_alias=current_session)
                            
                            client = await self.session_manager.get_client(current_session, use_proxy=task.use_proxy)
                            if not client:
                                raise Exception(f"Failed to get client for session {current_session}")
                
                # Check replies count if available (Pyrogram Message may not have .replies in all versions)
                replies_obj = getattr(post, 'replies', None)
                replies_count = getattr(replies_obj, 'replies', None) if replies_obj is not None else None
                if replies_count is not None and replies_count == 0:
                    logger.debug(f"üì≠ –ó–∞–¥–∞—á–∞ {task_id} - –ø–æ—Å—Ç {post.id} –Ω–µ –∏–º–µ–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, –ø—Ä–æ–ø—É—Å–∫")
                    continue
                if replies_count is not None:
                    logger.info(f"üí¨ –ó–∞–¥–∞—á–∞ {task_id} - –ø–æ—Å—Ç {post.id} –∏–º–µ–µ—Ç {replies_count} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, –æ–±—Ä–∞–±–æ—Ç–∫–∞...")
                else:
                    logger.info(f"üí¨ –ó–∞–¥–∞—á–∞ {task_id} - –ø–æ—Å—Ç {post.id}, –∑–∞–ø—Ä–æ—Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤...")
                
                try:
                    # Get discussion/comments for this post
                    # Note: Pyrogram uses get_discussion_replies to get comments
                    async for comment in client.get_discussion_replies(
                        chat_id=task.source_group_id,
                        message_id=post.id
                    ):
                        # Get comment author
                        user = comment.from_user
                        if not user or user.is_bot:
                            continue
                        
                        comment_user_id = user.id
                        
                        # Skip if already saved or seen in this run
                        if comment_user_id in already_saved_ids or comment_user_id in seen_user_ids:
                            continue
                        
                        # Get comment text
                        comment_text = comment.text or comment.caption or ""
                        comment_text_lower = comment_text.lower()
                        
                        # Check for keywords
                        has_keyword = False
                        if task.keyword_filter:
                            for keyword in task.keyword_filter:
                                if keyword.lower() in comment_text_lower:
                                    has_keyword = True
                                    break
                        else:
                            # No keyword filter = all match
                            has_keyword = True
                        
                        if not has_keyword:
                            continue
                        
                        # Check for exclude keywords
                        has_exclude = False
                        if task.exclude_keywords:
                            for exclude_word in task.exclude_keywords:
                                if exclude_word.lower() in comment_text_lower:
                                    has_exclude = True
                                    break
                        
                        if has_exclude:
                            continue
                        
                        # User matches keyword criteria - mark as seen and add to unique count
                        seen_user_ids.add(comment_user_id)
                        total_unique_users += 1
                        
                        user_data = {
                            'id': comment_user_id,
                            'username': user.username,
                            'first_name': user.first_name,
                            'last_name': user.last_name
                        }
                        user_info = f"{user_data.get('username') or user_data.get('id')}"
                        
                        # Apply admin filter if enabled
                        if task.filter_admins:
                            try:
                                source_member = await client.get_chat_member(task.source_group_id, comment_user_id)
                                raw_status = source_member.status
                                status_str = getattr(raw_status, "name", str(raw_status)).upper()
                                
                                if status_str in ['ADMINISTRATOR', 'CREATOR', 'OWNER']:
                                    logger.info(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø—Ä–æ–ø—É—Å–∫ –∞–¥–º–∏–Ω–∞: {user_info}")
                                    continue
                            except Exception as e:
                                logger.warning(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∞–¥–º–∏–Ω–∞ –¥–ª—è {user_info}: {e}")
                        
                        # Apply inactive filter if enabled
                        if task.filter_inactive and task.inactive_threshold_days is not None:
                            try:
                                users = await client.get_users([comment_user_id])
                                if users:
                                    user_obj = users[0]
                                    user_last_online = getattr(user_obj, 'last_online_date', None)
                                    
                                    if user_last_online is not None:
                                        from datetime import datetime, timedelta
                                        threshold_date = datetime.now() - timedelta(days=task.inactive_threshold_days)
                                        
                                        if user_last_online < threshold_date:
                                            days_since_online = (datetime.now() - user_last_online).days
                                            logger.info(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –ø—Ä–æ–ø—É—Å–∫ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ–≥–æ: {user_info} ({days_since_online} –¥–Ω.)")
                                            continue
                            except Exception as e:
                                logger.warning(f"üîç –ó–∞–¥–∞—á–∞ {task_id} - –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è {user_info}: {e}")
                        
                        # User passed all filters - add to unsaved list
                        unsaved_members.append(user_data)
                        self.task_unsaved_members[task_id] = unsaved_members
                        already_saved_ids.add(comment_user_id)
                        
                        logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} - –Ω–∞–π–¥–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å #{total_unique_users}: {user_info} (–∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤)")
                        
                        # Update messages offset in DB for resume capability
                        await self.db.update_parse_task(task_id, messages_offset=processed_posts, parsed_count=total_unique_users)
                        
                        # Check for incremental save by unique users found
                        if task.save_every_users > 0 and len(unsaved_members) >= task.save_every_users:
                            saved_count = await self._save_users_incremental(task, unsaved_members)
                            await self.db.update_parse_task(task_id, saved_count=saved_count)
                            unsaved_members = []
                            self.task_unsaved_members[task_id] = unsaved_members
                            logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(unsaved_members)} –ø–æ–ª—å–∑., –≤—Å–µ–≥–æ –≤ —Ñ–∞–π–ª–µ: {saved_count}")
                
                except Exception as e:
                    logger.error(f"‚ùå –ó–∞–¥–∞—á–∞ {task_id} - –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –ø–æ—Å—Ç–∞ {post.id}: {e}")
                    # Continue with next post
                    continue
            
            # Save remaining users
            if unsaved_members:
                saved_count = await self._save_users_incremental(task, unsaved_members)
                await self.db.update_parse_task(task_id, saved_count=saved_count)
                logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: –≤—Å–µ–≥–æ –≤ —Ñ–∞–π–ª–µ {saved_count} –ø–æ–ª—å–∑.")
                unsaved_members = []
                self.task_unsaved_members[task_id] = unsaved_members
            
            # Mark as completed
            await self.db.update_parse_task(task_id, status='completed')
            logger.info(f"üéâ –ó–∞–¥–∞—á–∞ {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_posts} –ø–æ—Å—Ç–æ–≤, –Ω–∞–π–¥–µ–Ω–æ {total_unique_users} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.")
            
            # Notify user
            await self._notify_user(
                user_id,
                f"‚úÖ **–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!**\n\n"
                f"üìù –§–∞–π–ª: `{task.file_name}`\n"
                f"üì¢ –ö–∞–Ω–∞–ª: {task.source_group_title}\n"
                f"üìã –†–µ–∂–∏–º: –∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫–∞–Ω–∞–ª–∞\n"
                f"üì® –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–æ—Å—Ç–æ–≤: {processed_posts}\n"
                f"üë• –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {total_unique_users}\n"
                f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Ñ–∞–π–ª: {saved_count}"
            )
            
        except asyncio.CancelledError:
            logger.info(f"‚èπÔ∏è –ó–∞–¥–∞—á–∞ {task_id} –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            # Save unsaved data
            if unsaved_members:
                saved_count = await self._save_users_incremental(task, unsaved_members)
                await self.db.update_parse_task(task_id, saved_count=saved_count)
                logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(unsaved_members)} –ø–æ–ª—å–∑. –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ, –≤—Å–µ–≥–æ: {saved_count}")
            await self.db.update_parse_task(task_id, status='paused')
            
            # Notify user
            await self._notify_user(
                user_id,
                f"‚è∏Ô∏è **–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω**\n\n"
                f"üìù –§–∞–π–ª: `{task.file_name}`\n"
                f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Ñ–∞–π–ª: `{saved_count}` –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
            )
        except Exception as e:
            error_str = str(e)
            logger.error(f"üí• –ó–∞–¥–∞—á–∞ {task_id} –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π: {error_str}", exc_info=True)
            
            # Check if it's a flood wait error and we can rotate
            is_flood_wait = 'FloodWait' in error_str or 'flood' in error_str.lower()
            
            if is_flood_wait and task.rotate_sessions and len(available_sessions) > 1:
                logger.warning(f"‚ö†Ô∏è –ó–∞–¥–∞—á–∞ {task_id} - –æ–±–Ω–∞—Ä—É–∂–µ–Ω FloodWait, –ø–æ–ø—ã—Ç–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏ —Å–µ—Å—Å–∏–∏...")
                
                # Save unsaved data first
                if unsaved_members:
                    try:
                        saved_count = await self._save_users_incremental(task, unsaved_members)
                        await self.db.update_parse_task(task_id, saved_count=saved_count)
                        logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(unsaved_members)} –ø–æ–ª—å–∑. –ø–µ—Ä–µ–¥ —Ä–æ—Ç–∞—Ü–∏–µ–π")
                    except Exception as save_error:
                        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ: {save_error}")
                
                # Try rotating to next session
                try:
                    current_index = available_sessions.index(current_session)
                except ValueError:
                    current_index = -1
                
                next_index = (current_index + 1) % len(available_sessions)
                next_session = available_sessions[next_index]
                
                if next_session != current_session:
                    logger.info(f"üîÑ –ó–∞–¥–∞—á–∞ {task_id} - —Ä–æ—Ç–∞—Ü–∏—è –∏–∑-–∑–∞ FloodWait: {current_session} -> {next_session}")
                    await self.db.update_parse_task(task_id, session_alias=next_session, status='paused')
                    await self._notify_user(
                        user_id,
                        f"‚ö†Ô∏è **FloodWait –Ω–∞ —Å–µ—Å—Å–∏–∏ {current_session}**\n\n"
                        f"–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –°–µ—Å—Å–∏—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∞ –Ω–∞ `{next_session}`.\n"
                        f"–ù–∞–∂–º–∏—Ç–µ '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å' —á—Ç–æ–±—ã –≤–æ–∑–æ–±–Ω–æ–≤–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥."
                    )
                    return
            
            # Save unsaved data on error
            if unsaved_members:
                try:
                    saved_count = await self._save_users_incremental(task, unsaved_members)
                    await self.db.update_parse_task(task_id, saved_count=saved_count)
                    logger.info(f"üíæ –ó–∞–¥–∞—á–∞ {task_id} - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(unsaved_members)} –ø–æ–ª—å–∑. –ø—Ä–∏ –æ—à–∏–±–∫–µ, –≤—Å–µ–≥–æ: {saved_count}")
                except Exception as save_error:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ: {save_error}")
            
            await self.db.update_parse_task(
                task_id,
                status='failed',
                error_message=error_str
            )
            await self._notify_user(
                user_id,
                f"‚ùå **–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞!**\n\n"
                f"–ó–∞–¥–∞—á–∞: `{task.file_name}`\n"
                f"–û—à–∏–±–∫–∞: `{error_str}`"
            )
        finally:
            if task_id in self.running_tasks:
                del self.running_tasks[task_id]
            if task_id in self.task_unsaved_members:
                del self.task_unsaved_members[task_id]
            if task_id in self.task_metadata:
                del self.task_metadata[task_id]

